{% extends "global/Page.html" %}
{% load otree static %}

{% block title %}
    Explaining the algorithm's output
{% endblock %}

{% block content %}

{%comment &}
    <br/>
    <br/>


    <h4>What kind?</h4>
    <p>
        The algorithm can be categorized as <strong>boosted tree ensemble method</strong>.<br/>
        Single decision trees build
    </p>
{%endcomment %}
    <p>
        In order to understand how ML algorithms arrive at a certain output value, the depiction of the importance of
        features used by the algorithm can be helpful. The now introduced method to determine feature importance for
        complex ML algorithms is grounded on mathematical game theory. Furthermore, studies suggest that the assigned
        feature importance is in accordance to human intuition. The method is capable of providing the feature importance
        for a single data point (e.g. the next one to predict) at a time and is hence a local method. The importance
        assigned to a single feature can vary from data point to data point.
        <br/>
        The graph below shows how the feature importance with the respective impact on the algorithm's output can be visualized.
        <ul>
            <li>The "base value" is the value the model would predict on average (without information about the values of the input features). </li>
            <li>The "output value" is the actual output for the single data point depicted. </li>
            <li>Starting from the "base value", the features with an arrow pointing to the right "push" the actual output to higher values. </li>
            <li>Starting from the "base value", the features with an arrow pointing to the left "push" the actual output to lower values. </li>
            <li>The result of the "pushing" is where the "output value" ends up. </li>
            <li>Only features that contribute to at least 10% are depicted. A single feature's contribution might change from data point to data point. </li>

                <ul>
                    <li>Total: Average of all previous data points</li>
                    <li>Year: Average of all previous data points which have the same year value as the upcoming forecast to
                    be made (e.g. all data points of 2017)</li>
                    <li>Quarter: Average of all previous data points which have the same quarter value as the upcoming forecast to
                    be made (e.g. all data points in first quarter, no matter which year) </li>
                    <li>Month: Average of all previous data points which have the same month value as the upcoming forecast to
                    be made (e.g. all historical data points in January, no matter which year)</li>
                    <li>Week: Average of all previous data points which have the same week value as the upcoming forecast to
                    be made (e.g. all data points of calender week 42, no matter which year)</li>
                    <li>Weekday: Average of all previous data points which have the same weekday value as the upcoming forecast to
                    be made (e.g. all data points on a Monday, no matter which week, month, quarter or year)</li>
                </ul>
            <li>Past actual values (9 features)</li>
                <ul>
                    <li>Actual demand value 1-6 days ago (6 features) </li>
                    <li>Actual demand value 1 week ago </li>
                    <li>Actual demand value 1 month ago (4*7 days) </li>
                    <li>Actual demand value 1 year ago (52*7 days) </li>
                </ul>
        </ul>
    </p>

<img src="{% static "global/xplainUnderstand1.png" %}" width="950"/>

{%comment%}
    <h4>How good?</h4>
    <p>
        The algorithm was put together by thoughtful analysts and has an average accuracy of ~92%.
        (TBD) "a sophisticated model, put together by thoughtful analysts"
    </p>
{%endcomment%}

    {% next_button %}

{% endblock %}